{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zeez ðŸ˜´\n",
    "\n",
    "_sleep improvement using wearables and n-of-1 experiments_\n",
    "\n",
    "[Project Homepage](http://people.ischool.berkeley.edu/~marcelo.queiroz/Zeez/ \"Zeez Project Homepage\") \n",
    "\n",
    "## Data Ingestion, Transformation, and Modeling Notebook\n",
    "\n",
    "This notebook showcases an ETL pipeline for:\n",
    "1. ingesting Oura telemetry and Bioloop experiment data via API\n",
    "2. parsing data into one-record-per-person-per-day form\n",
    "3. feature engineering\n",
    "4. model training\n",
    "5. model saving for reuse in production\n",
    "\n",
    "## Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# packages for ETL\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "from zipfile import ZipFile\n",
    "from datetime import datetime, date\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# timing facilities\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "main_time_counter = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Helper functions for ETL and feature engineering:\n",
    "\n",
    "def decode_stacked_json(stacked_json_string, pos=0, decoder=json.JSONDecoder()):\n",
    "    \"\"\"Yield multiple JSON objects and restart parsing from the previous position\n",
    "    Input must be of the form: {'key1': value1, 'key2': value2}{'key3': value3, 'key4': value4\"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            json_object, pos = decoder.raw_decode(stacked_json_string, pos)\n",
    "        except json.JSONDecodeError:\n",
    "            break\n",
    "        yield json_object\n",
    "       \n",
    "        \n",
    "def after_wake_exercise(class_5min,bedtime_end):\n",
    "    \"\"\"returns the number of minutes with medium to high MET scores \n",
    "    within the first 3 hours of wake-time as a proxy for whether or not exercise \n",
    "    occurs after waking up\"\"\"\n",
    "    if isinstance(class_5min,float) or isinstance(bedtime_end, float):\n",
    "        return np.nan\n",
    "    else:\n",
    "        #convert the str integer into a list of integers\n",
    "        class_5min_list = list(map(int, class_5min))\n",
    "        #--take the timestamp from the datetime string, extracts hh:mm data, and converts to a number--#\n",
    "        wake_hr_min = int(''.join(bedtime_end.split('T')[1][0:5].split(':')))\n",
    "        #---calculate minutes lapsed since 4am and wake up time---#\n",
    "        #---rescale minutes into 5 minute intervals to find the number of elements at which to offset class_5min--#\n",
    "        offset = int(((wake_hr_min - 400)/100)*(60/5))\n",
    "\n",
    "        #subset observations between wake up and 3 hrs post wake up (24*5=120 min)\n",
    "        morning_obs = class_5min_list[offset:offset+36]\n",
    "\n",
    "        #tally total minutes spent in medium to high intensity exercise (3-4)\n",
    "        total_min = sum([1 for obs in morning_obs if obs >=3])*5\n",
    "        return total_min\n",
    "\n",
    "\n",
    "def before_sleep_exercise(class_5min,bedtime_start):\n",
    "    \"\"\"returns the number of minutes with medium to high MET scores \n",
    "    within the last 3 hours of wake-time as a proxy for whether or not exercise \n",
    "    occurs in the evening close to bedtime\"\"\"\n",
    "    if isinstance(class_5min,float) or isinstance(bedtime_start, float):\n",
    "        return np.nan\n",
    "    else:\n",
    "        #convert the str integer into a list of integers\n",
    "        class_5min_list = list(map(int, class_5min))\n",
    "        #--take the timestamp from the datetime string, extracts hh:mm data, and converts to a number--#\n",
    "        sleep_hr_min = int(''.join(bedtime_start.split('T')[1][0:5].split(':')))\n",
    "        #---calculate minutes lapsed since 4am and wake up time---#\n",
    "        #---rescale minutes into 5 minute intervals to find the number of elements at which to offset class_5min--#\n",
    "        offset = int(((sleep_hr_min - 400)/100)*(60/5))\n",
    "\n",
    "        #subset observations 3 hours before sleep time\n",
    "        evening_obs = class_5min_list[offset-36:offset]\n",
    "\n",
    "        #tally total minutes spent in medium to high intensity exercise (3-4)\n",
    "        total_min = sum([1 for obs in evening_obs if obs >=3])*5\n",
    "        return total_min\n",
    "\n",
    "\n",
    "def noon_exercise(class_5min):\n",
    "    \"\"\"returns the number of minutes with medium to high MET scores \n",
    "    between noon and two local time\"\"\"\n",
    "    if isinstance(class_5min,float):\n",
    "        return np.nan\n",
    "    else:\n",
    "        #convert the str integer into a list of integers\n",
    "        class_5min_list = list(map(int, class_5min))\n",
    "\n",
    "        #---calculate minutes lapsed since 4am and 12 (8*12 (5min intervasl in an hr)---#\n",
    "\n",
    "        offset = 96\n",
    "\n",
    "        #subset observations between noon and 2 pm\n",
    "        noon_obs = class_5min_list[offset:offset+24]\n",
    "\n",
    "        #tally total minutes spent in medium to high intensity exercise (3-4)\n",
    "        total_min = sum([1 for obs in noon_obs if obs >=3])*5\n",
    "        return total_min\n",
    " \n",
    "    \n",
    "def evening_exercise(class_5min):\n",
    "    \"\"\"returns the number of minutes with medium to high MET scores \n",
    "    between noon and two local time\"\"\"\n",
    "    if isinstance(class_5min, float):\n",
    "        return np.nan\n",
    "    else:\n",
    "        #convert the str integer into a list of integers\n",
    "        class_5min_list = list(map(int, class_5min))\n",
    "\n",
    "        #---calculate minutes lapsed since 4am and 5pm (13*12) --there are 12 5min intervasl in an hr---#\n",
    "\n",
    "        offset = 156\n",
    "\n",
    "        #subset observations between 5pm and 7 pm post wake up\n",
    "        eve_obs = class_5min_list[offset:offset+24]\n",
    "\n",
    "        #tally total minutes spent in medium to high intensity exercise (3-4)\n",
    "        total_min = sum([1 for obs in eve_obs if obs >=3])*5\n",
    "        return total_min\n",
    "\n",
    "\n",
    "def after_midnight(timestamp_str):\n",
    "    \"\"\"indicator for whether or not bedtime started after midnight (in early am hours)\"\"\"\n",
    "    try:\n",
    "        day, hour = timestamp_str.split('T')\n",
    "        hr = int(hour[0:2]) #extract hr from timestamp\n",
    "        if 0 <= hr < 6:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def age_bin(e):\n",
    "    \"\"\"Bins: 20s, 30s, 40s, and 50s +\"\"\"\n",
    "    if  20 <= e < 30:\n",
    "        return \"20s\"\n",
    "    elif 30 <= e < 40:\n",
    "        return \"30s\"\n",
    "    elif 40 <= e < 50:\n",
    "        return \"40s\"\n",
    "    elif e > 50:\n",
    "        return \"50s plus\"\n",
    "    else:\n",
    "        return np.nan\n",
    "   \n",
    "    \n",
    "def height_bin(e):\n",
    "    \"\"\"Bins: 0, 150, 160, 170, 180, 190. In centimeters \"\"\"\n",
    "    if  0 < e < 150:\n",
    "        return \"less than 150 cm\"\n",
    "    elif 150 <= e <= 160:\n",
    "        return \"150s\"\n",
    "    elif 160 <= e <= 170:\n",
    "        return \"160s\"\n",
    "    elif 170 <= e <= 180:\n",
    "        return \"170s\"\n",
    "    elif 180 <= e <= 190:\n",
    "        return \"180s\"\n",
    "    elif e > 190:\n",
    "        return \"greater than 190 cm\"\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "    \n",
    "def weight_bin(e):\n",
    "    \"\"\"Bins: 0, 65, 80, 95. In kilograms\"\"\"\n",
    "    if  0 < e <=65:\n",
    "        return \"less than 65 kg\"\n",
    "    elif 65 <= e <= 80:\n",
    "        return \"65 to 80 kg\"\n",
    "    elif 80 <= e <= 95:\n",
    "        return \"80 to 95 kg\"\n",
    "    elif e > 95:\n",
    "        return \"more than 95 kg\"\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def experiments_recategorize(e):\n",
    "    '''helper function to recategorize experiment types:\n",
    "    broader categories will be Magnesium, Chamomile tea, Meditation and Other'''\n",
    "    if pd.isnull(e):\n",
    "        return 'None'\n",
    "    elif 'Meditat' in e:\n",
    "        return 'Meditation'\n",
    "    elif 'Magnesium' in e:\n",
    "        return 'Magnesium'\n",
    "    elif 'Chamomile' in e:\n",
    "        return 'Chamomile Tea'\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define data ingestion location\n",
    "full_path = 'data_ingestion/{}'.format(date.today().strftime('%Y-%m-%d'))\n",
    "os.makedirs(full_path, exist_ok=True)\n",
    "\n",
    "# get secret connection credentials\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# start timing\n",
    "script_time_start = time.time()\n",
    "\n",
    "# read .env file\n",
    "load_dotenv()\n",
    "\n",
    "# extract .env constants\n",
    "BIOLOOP_CONNECTION_URL     = os.getenv(\"BIOLOOP_CONNECTION_URL\")\n",
    "BIOLOOP_CONNECTION_TOKEN   = os.getenv(\"BIOLOOP_CONNECTION_TOKEN\")\n",
    "\n",
    "# create a simple \"log file\" on the log ingestion directory. Can be helpful to debug and later on for feature monitoring.\n",
    "log_file = open(full_path + '/log.txt', 'a+')\n",
    "log_file.write(time.asctime() + ' - Starting data ingestion process\\n')\n",
    "\n",
    "# if a data file exists, load it, otherwise, create the directory, download a new one and load the DFs:\n",
    "if not os.path.isfile(full_path + '/raw_dataset.zip'):    \n",
    "    start = time.time() # time the data ingestion from Memento\n",
    "    log_file.write(time.asctime() + ' - Day file not found. Starting data download\\n')\n",
    "    \n",
    "    # try: \n",
    "    ACCESS_TOKEN = '###'\n",
    "    headers = {'Authorization': 'Bearer ' + BIOLOOP_CONNECTION_TOKEN }\n",
    "    URL = BIOLOOP_CONNECTION_URL\n",
    "    # changed this code to deal with streaming json from 10/20/2019 on. Must double check if this will be the final \n",
    "    # format\n",
    "    data = requests.get(URL, headers=headers).content.decode(encoding='utf-8')\n",
    "\n",
    "    # save the raw data to disk as zip it to allow re-processing without new download\n",
    "    zip_file = full_path + '/raw_dataset.zip'\n",
    "    zipObj = ZipFile(zip_file, 'w', compression=zipfile.ZIP_DEFLATED)\n",
    "    zipObj.writestr('raw_dataset.txt', data)\n",
    "    zipObj.close()\n",
    "\n",
    "    # print('total run time:',time.time() - start)\n",
    "    log_file.write(time.asctime() + ' - JSON File downloaded and saved. Time: ' + f'{(time.time() - start):.1f}' + ' secs.\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform To One Dataframe Per Type - Experiments, Sleep, Activity, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define intermediate data frames:\n",
    "users = pd.DataFrame()\n",
    "sleep = pd.DataFrame()\n",
    "readiness = pd.DataFrame()\n",
    "activity = pd.DataFrame()\n",
    "experiments = pd.DataFrame()\n",
    "\n",
    "# timing and logging\n",
    "start = time.time()\n",
    "raw_data = str(zipfile.ZipFile(full_path + '/raw_dataset.zip').read('raw_dataset.txt'), encoding='utf-8')\n",
    "log_file.write(time.asctime() + ' - raw data file loaded. Time: ' + f'{(time.time() - start):.1f}' + ' secs.\\n')\n",
    "\n",
    "start = time.time()\n",
    "log_file.write(time.asctime() + ' - creating feature space\\n')\n",
    "\n",
    "active_user_counter = 0\n",
    "xp_counter = 0\n",
    "\n",
    "for user_json in decode_stacked_json(raw_data):\n",
    "    # in the stacked json file, each json object corresponds to all data of one user. So here I will perform all \n",
    "    # feature transformation that are user-dependent before I append the whole user data to a final data frame.\n",
    "    user_user = pd.DataFrame.from_records([user_json['userInfo']['userInfo']])\n",
    "    \n",
    "    try: # user signup date may be useful to define if a user model is relevant or not:\n",
    "        user_user['signupDate'] = pd.to_datetime(user_json['signupDate'])\n",
    "    except KeyError:\n",
    "        user_user['signupDate'] = np.nan\n",
    "\n",
    "    # one hot encode gender data:\n",
    "    try:\n",
    "        user_user['gender'] = np.where(user_user['gender'] == 'male', True, False)\n",
    "    except KeyError:\n",
    "        user_user['gender'] = np.nan\n",
    "\n",
    "    user_user.rename(columns={'gender':'is_male'}, inplace=True)\n",
    "\n",
    "    try:\n",
    "        user_user['age'] = user_user['age']\n",
    "    except KeyError:\n",
    "        user_user['age'] = np.nan\n",
    "\n",
    "    try:\n",
    "        user_user['height'] = user_user['height']\n",
    "    except KeyError:\n",
    "        user_user['height'] = np.nan\n",
    "\n",
    "    try:\n",
    "        user_user['weight'] = user_user['weight']\n",
    "    except KeyError:\n",
    "        user_user['weight'] = np.nan\n",
    "\n",
    "    # send to a final users data frame:\n",
    "    users = users.append(user_user)\n",
    "\n",
    "    # skip users without sleep records (strictly experiment users, or users of other hardware)\n",
    "    if len(user_json['sleep']) == 0: continue\n",
    "    active_user_counter += 1\n",
    "\n",
    "    # unpack data for each user in a specific data frame\n",
    "    user_sleep = pd.DataFrame.from_records([i for i in user_json['sleep']])\n",
    "    user_readiness = pd.DataFrame.from_records([i for i in user_json['readiness']])\n",
    "    user_activity = pd.DataFrame.from_records([i for i in user_json['activity']])\n",
    "\n",
    "    # each DF has a `score` feature. Renaming to avoid later confusion:\n",
    "    user_sleep.rename(columns = {'score':'sleep_score'}, inplace=True)\n",
    "    user_activity.rename(columns = {'score':'activity_score'}, inplace=True)\n",
    "    user_readiness.rename(columns = {'score':'readiness_score'}, inplace=True)\n",
    "\n",
    "    #### ---------- SLEEP FEATURES ----------- ####\n",
    "    # sleep features normalizing and transformations:\n",
    "    user_sleep['awake_norm'] = user_sleep['awake']/user_sleep['duration']\n",
    "    user_sleep['deep_norm'] = user_sleep['deep']/user_sleep['duration']\n",
    "    user_sleep['light_norm'] = user_sleep['light']/user_sleep['duration']\n",
    "    user_sleep['onset_latency_norm'] = user_sleep['onset_latency']/user_sleep['duration']\n",
    "    user_sleep['rem_norm'] = user_sleep['rem']/user_sleep['duration']\n",
    "    user_sleep['restless_norm'] = user_sleep['light']/100\n",
    "\n",
    "    # bins for sleep score to Shiraz's models:\n",
    "    bins = [0, 75, 85, 100]\n",
    "    names = ['fair', 'good', 'greate']\n",
    "    user_sleep['good_sleep'] = pd.cut(user_sleep['sleep_score'], bins=bins, labels=names)\n",
    "\n",
    "    # creating new sleep features:\n",
    "    user_sleep['summary_date'] = pd.to_datetime(user_sleep['summary_date'])\n",
    "    user_sleep['user_id'] = user_user['user_id'][0]\n",
    "    user_sleep['user_date'] = user_sleep['user_id'] + '|' + user_sleep['summary_date'].astype('str')\n",
    "\n",
    "    user_sleep.set_index('summary_date', inplace = True, drop=False)\n",
    "\n",
    "    # build D - 1 and D - 2 scores:\n",
    "    user_sleep['sleep_score_D-1'] = user_sleep['sleep_score'].shift()[user_sleep.index.shift(1,freq='1D')]\n",
    "    user_sleep['sleep_score_D-2'] = user_sleep['sleep_score'].shift()[user_sleep.index.shift(1,freq='2D')]\n",
    "    user_sleep['deep_D-1'] = user_sleep['deep'].shift()[user_sleep.index.shift(1,freq='1D')]\n",
    "    user_sleep['deep_D-2'] = user_sleep['deep'].shift()[user_sleep.index.shift(1,freq='2D')]\n",
    "    user_sleep['rem_D-1'] = user_sleep['rem'].shift()[user_sleep.index.shift(1,freq='1D')]\n",
    "    user_sleep['rem_D-2'] = user_sleep['rem'].shift()[user_sleep.index.shift(1,freq='2D')]\n",
    "\n",
    "    # build 7, 14, and 21 rolling average scores:\n",
    "    user_sleep['rol_sleep_score_7d'] = pd.DataFrame.rolling(user_sleep['sleep_score'].shift(1, freq='1D'),\n",
    "                                                      window=7, min_periods=3).mean()\n",
    "    # shifted 7 day score rolled feature. This is target feature to predict your average 7 days ahead\n",
    "    user_sleep['avg_sleep_score_next_week'] = user_sleep['rol_sleep_score_7d'].shift(-1,freq='7D')\n",
    "\n",
    "    user_sleep['rol_sleep_score_14d'] = pd.DataFrame.rolling(user_sleep['sleep_score'].shift(1, freq='1D'),\n",
    "                                                      window=14, min_periods=10).mean()\n",
    "    user_sleep['rol_sleep_score_21d'] = pd.DataFrame.rolling(user_sleep['sleep_score'].shift(1, freq='1D'),\n",
    "                                                      window=21, min_periods=17).mean()\n",
    "\n",
    "    # build other 7-day rolling features for peter's models later:\n",
    "    user_sleep['rol_bedtime_end_delta_7d'] = pd.DataFrame.rolling(user_sleep['bedtime_end_delta'].shift(1, freq='1D'),\n",
    "                                                            window=7, min_periods=3).mean()\n",
    "    user_sleep['rol_bedtime_start_delta_7d'] = pd.DataFrame.rolling(user_sleep['bedtime_start_delta'].shift(1, freq='1D'),\n",
    "                                                                    window=7, min_periods=3).mean()\n",
    "    user_sleep['rol_onset_latency_7d'] = pd.DataFrame.rolling(user_sleep['onset_latency'].shift(1, freq='1D'),\n",
    "                                                              window=7, min_periods=3).mean()\n",
    "    user_sleep['rol_duration_7d'] = pd.DataFrame.rolling(user_sleep['duration'].shift(1, freq='1D'),\n",
    "                                                         window=7, min_periods=3).mean()\n",
    "\n",
    "    # build is_traveling\n",
    "    user_sleep['is_traveling'] = np.where(user_sleep['timezone'] == \n",
    "                                                    user_sleep['timezone'].value_counts().idxmax(), False, True)\n",
    "    \n",
    "    user_sleep['tz_delta'] = (user_sleep['timezone'] - user_sleep['timezone'].value_counts().idxmax()) / (-60)\n",
    "    \n",
    "    # build rol_bedtime_start_21d\n",
    "    user_sleep['rol_bedtime_start_21d'] = pd.DataFrame.rolling(user_sleep['bedtime_start_delta'].shift(1, freq='1D'),\n",
    "                                                                 window=21, min_periods=10).mean()\n",
    "\n",
    "    # build avg_bedtime_start_delta, create dummy variables for deviation (-3, -2, -1, 1, 2, 3)\n",
    "    user_sleep['rol_bedtime_start_std_21d'] = pd.DataFrame.rolling(user_sleep['bedtime_start_delta'].shift(1, freq='1D'),\n",
    "                                                                 window=21, min_periods=10).std()\n",
    "\n",
    "    user_sleep['bedtime_start_dev'] = (user_sleep['bedtime_start_delta'] - user_sleep['rol_bedtime_start_21d'])/\\\n",
    "                                      user_sleep['rol_bedtime_start_std_21d']\n",
    "\n",
    "    user_sleep['bedtime_start_dev'] = np.where(user_sleep['bedtime_start_dev'] >= 0, \n",
    "                                                        np.ceil(user_sleep['bedtime_start_dev']),\n",
    "                                                        np.floor(user_sleep['bedtime_start_dev']))\n",
    "    # cap standard deviations to -3 or +3:\n",
    "    user_sleep['bedtime_start_dev'] = np.where(user_sleep['bedtime_start_dev'] <= -3,-3, user_sleep['bedtime_start_dev'])\n",
    "\n",
    "    user_sleep['bedtime_start_dev'] = np.where(user_sleep['bedtime_start_dev'] >= 3,3,\n",
    "                                                        user_sleep['bedtime_start_dev'])\n",
    "\n",
    "    user_sleep = pd.get_dummies(user_sleep, columns=['bedtime_start_dev'])\n",
    "\n",
    "    user_sleep.rename(columns = { 'bedtime_start_dev_-3.0':'bedtime_start_dev-3', \n",
    "                                  'bedtime_start_dev_-2.0':'bedtime_start_dev-2', \n",
    "                                  'bedtime_start_dev_-1.0': 'bedtime_start_dev-1',\n",
    "                                  'bedtime_start_dev_1.0': 'bedtime_start_dev+1',\n",
    "                                  'bedtime_start_dev_2.0': 'bedtime_start_dev+2',\n",
    "                                  'bedtime_start_dev_3.0': 'bedtime_start_dev+3'},\n",
    "                                  inplace = True)\n",
    "\n",
    "    user_sleep.drop(labels = ['rol_bedtime_start_21d','rol_bedtime_start_std_21d'], axis = 1, inplace = True)\n",
    "\n",
    "    # build avg_bedtime_end_delta, create dummy variables for deviation. (-3, -2, -1, 1, 2, 3)\n",
    "    user_sleep['rol_bedtime_end_21d'] = pd.DataFrame.rolling(user_sleep['bedtime_end_delta'].shift(1, freq='1D'),\n",
    "                                                                 window=21, min_periods=10).mean()\n",
    "\n",
    "    user_sleep['rol_bedtime_end_std_21d'] = pd.DataFrame.rolling(user_sleep['bedtime_end_delta'].shift(1, freq='1D'),\n",
    "                                                                 window=21, min_periods=10).std()\n",
    "\n",
    "    user_sleep['bedtime_end_dev'] = (user_sleep['bedtime_end_delta'] - user_sleep['rol_bedtime_end_21d'])/\\\n",
    "                                    user_sleep['rol_bedtime_end_std_21d']\n",
    "\n",
    "    user_sleep['bedtime_end_dev'] = np.where(user_sleep['bedtime_end_dev'] >= 0, \n",
    "                                             np.ceil(user_sleep['bedtime_end_dev']),\n",
    "                                             np.floor(user_sleep['bedtime_end_dev']))\n",
    "    # cap standard deviations to -3 or +3:\n",
    "    user_sleep['bedtime_end_dev'] = np.where(user_sleep['bedtime_end_dev'] <= -3,-3,\n",
    "                                             user_sleep['bedtime_end_dev'])\n",
    "\n",
    "    user_sleep['bedtime_end_dev'] = np.where(user_sleep['bedtime_end_dev'] >= 3,3,\n",
    "                                             user_sleep['bedtime_end_dev'])\n",
    "\n",
    "    user_sleep = pd.get_dummies(user_sleep, columns=['bedtime_end_dev'])\n",
    "\n",
    "    user_sleep.rename(columns = {'bedtime_end_dev_-3.0':'bedtime_end_dev-3', \n",
    "                                 'bedtime_end_dev_-2.0':'bedtime_end_dev-2', \n",
    "                                 'bedtime_end_dev_-1.0': 'bedtime_end_dev-1',\n",
    "                                 'bedtime_end_dev_1.0': 'bedtime_end_dev+1',\n",
    "                                 'bedtime_end_dev_2.0': 'bedtime_end_dev+2',\n",
    "                                 'bedtime_end_dev_3.0': 'bedtime_end_dev+3'},\n",
    "                                 inplace = True)\n",
    "\n",
    "    user_sleep.drop(labels = ['rol_bedtime_end_21d','rol_bedtime_end_std_21d'], axis = 1, inplace = True)\n",
    "\n",
    "    # build avg_duration, create dummy variables for deviation (-3, -2, -1, 1, 2, 3)\n",
    "    user_sleep['rol_duration_21d'] = pd.DataFrame.rolling(user_sleep['duration'].shift(1, freq='1D'),\n",
    "                                                                 window=21, min_periods=10).mean()\n",
    "\n",
    "    user_sleep['rol_duration_std_21d'] = pd.DataFrame.rolling(user_sleep['duration'].shift(1, freq='1D'),\n",
    "                                                                 window=21, min_periods=10).std()\n",
    "\n",
    "    user_sleep['duration_dev'] = (user_sleep['duration'] - user_sleep['rol_duration_21d'])/\\\n",
    "                                 user_sleep['rol_duration_std_21d']\n",
    "\n",
    "    user_sleep['duration_dev'] = np.where(user_sleep['duration_dev'] >= 0, \n",
    "                                          np.ceil(user_sleep['duration_dev']),\n",
    "                                          np.floor(user_sleep['duration_dev']))\n",
    "\n",
    "    # cap standard deviations to -3 or +3:\n",
    "    user_sleep['duration_dev'] = np.where(user_sleep['duration_dev'] <= -3,-3, user_sleep['duration_dev'])\n",
    "\n",
    "    user_sleep['duration_dev'] = np.where(user_sleep['duration_dev'] >= 3,3, user_sleep['duration_dev'])\n",
    "\n",
    "    user_sleep = pd.get_dummies(user_sleep, columns=['duration_dev'])\n",
    "\n",
    "    user_sleep.rename(columns = {'duration_dev_-3.0':'duration_dev-3', \n",
    "                              'duration_dev_-2.0':'duration_dev-2', \n",
    "                              'duration_dev_-1.0':'duration_dev-1',\n",
    "                              'duration_dev_1.0': 'duration_dev+1',\n",
    "                              'duration_dev_2.0': 'duration_dev+2',\n",
    "                              'duration_dev_3.0': 'duration_dev+3'},\n",
    "                              inplace = True)\n",
    "\n",
    "    user_sleep.drop(labels = ['rol_duration_21d','rol_duration_std_21d'], axis = 1, inplace = True)\n",
    "\n",
    "    # build dummy to day of the week.\n",
    "    user_sleep['weekday'] = user_sleep['summary_date'].dt.weekday\n",
    "\n",
    "    # build is_workday\n",
    "    user_sleep['is_workday'] = np.where(user_sleep['weekday'] < 5, True, False)\n",
    "\n",
    "    # one-hot encode weekdays\n",
    "    user_sleep = pd.get_dummies(user_sleep, columns=['weekday'])\n",
    "\n",
    "    user_sleep.rename(columns = {'weekday_0':'weekday_mon', \n",
    "                              'weekday_1':'weekday_tue', \n",
    "                              'weekday_2': 'weekday_wed',\n",
    "                              'weekday_3': 'weekday_thu',\n",
    "                              'weekday_4': 'weekday_fri',\n",
    "                              'weekday_5': 'weekday_sat',\n",
    "                              'weekday_6': 'weekday_sun'}, \n",
    "                              inplace = True)\n",
    "\n",
    "    #rolling actionable sleep features\n",
    "    sleep_vars_to_roll = ['onset_latency','duration','is_traveling','score_disturbances']\n",
    "    \n",
    "    for feature in sleep_vars_to_roll :\n",
    "        user_sleep['rol_' + feature + '_7d'] = pd.DataFrame.rolling(user_sleep[feature].shift(1, freq='1D'),\n",
    "                                                      window=7, min_periods=3).mean()\n",
    "    \n",
    "    \n",
    "    #---Week-over-Week sleep behavior changes as proxy for sleep routine---#\n",
    "    user_sleep['rol_onset_latency_7d_WoW'] = user_sleep['rol_onset_latency_7d'].pct_change(periods=7)\n",
    "    user_sleep['rol_duration_7d_WoW'] = user_sleep['rol_duration_7d'].pct_change(periods=7)\n",
    "    user_sleep['rol_score_disturbances_7d_WoW'] = user_sleep['rol_score_disturbances_7d'].pct_change(periods=7)\n",
    "    user_sleep['rol_bedtime_start_delta_7d_WoW'] = user_sleep['rol_bedtime_start_delta_7d'].pct_change(periods=7)\n",
    "    \n",
    "    #sleep routine as the mean absolute value of WoW variables\n",
    "    user_sleep['sleep_routine_score'] = (\n",
    "    np.absolute(user_sleep['rol_onset_latency_7d_WoW']) + \n",
    "    np.absolute(user_sleep['rol_duration_7d_WoW']) +\n",
    "    np.absolute(user_sleep['rol_score_disturbances_7d_WoW'])+\n",
    "    np.absolute(user_sleep['rol_bedtime_start_delta_7d_WoW']))/4\n",
    "    \n",
    "    user_sleep.set_index('user_date', inplace = True)\n",
    "    sleep = sleep.append(user_sleep)\n",
    "\n",
    "\n",
    "    #### ---------- ACTIVITY FEATURES ----------- ####\n",
    "    # Creating the new activity related features. Because several activity features depends on user info and/or \n",
    "    # sleep features, I will add the features needed here:\n",
    "    user_activity['user_date'] = user_user['user_id'][0] + '|' + user_activity['summary_date'].astype('str')\n",
    "\n",
    "    user_activity['age'] = user_user['age'][0]\n",
    "    user_activity['height'] = user_user['height'][0]\n",
    "    user_activity['weight'] = user_user['weight'][0]\n",
    "    user_activity['is_male'] = user_user['is_male'][0]\n",
    "\n",
    "    user_activity['summary_date'] = pd.to_datetime(user_activity['summary_date'])   \n",
    "    user_activity = user_activity.merge(user_sleep[['bedtime_start', 'bedtime_end', 'summary_date']], \n",
    "                                        on='summary_date', how='left')\n",
    "\n",
    "    user_activity.set_index('summary_date', inplace = True, drop=False)\n",
    "\n",
    "    user_activity['met_min_medium_plus'] = user_activity['met_min_medium'] + \\\n",
    "                                                    user_activity['met_min_high']\n",
    "\n",
    "    user_activity['age_bin'] = user_activity['age'].apply(age_bin)\n",
    "    user_activity['height_bin'] = user_activity['height'].apply(height_bin)\n",
    "    user_activity['weight_bin'] = user_activity['weight'].apply(weight_bin)\n",
    "    user_activity['sleep_afterMidnight'] = user_activity['bedtime_start'].apply(after_midnight)\n",
    "    user_activity['afterwake_exercise_min'] = [after_wake_exercise(c,b) for c,b in \\\n",
    "                                               zip(user_activity['class_5min'],\n",
    "                                                   user_activity['bedtime_end'])]\n",
    "    user_activity['beforesleep_exercise_min'] = [before_sleep_exercise(c,b) for c,b in \\\n",
    "                                                 zip(user_activity['class_5min'],\n",
    "                                                     user_activity['bedtime_start'])]\n",
    "    user_activity['noon_exercise_min'] = user_activity['class_5min'].apply(noon_exercise)\n",
    "    user_activity['eve_exercise_min'] = user_activity['class_5min'].apply(evening_exercise)\n",
    "\n",
    "    # actionable activity variables that will be rolled within a 7 day window\n",
    "    activity_vars_to_roll = ['cal_total', 'high', 'medium','steps','inactive', \n",
    "                             'non_wear', 'activity_score','met_min_medium','sleep_afterMidnight',\n",
    "                             'met_min_high', 'met_min_medium_plus','score_move_every_hour',\n",
    "                             'score_stay_active', 'beforesleep_exercise_min',\n",
    "                             'afterwake_exercise_min','noon_exercise_min', 'eve_exercise_min']\n",
    "\n",
    "    for feature in activity_vars_to_roll :\n",
    "        user_activity['rol_' + feature + '_7d'] = pd.DataFrame.rolling(user_activity[feature].shift(1, freq='1D'),\n",
    "                                                      window=7, min_periods=3).mean()\n",
    "    \n",
    "    #---Week-over-Week activity behavior changes as proxy for activity routine---#\n",
    "    #note; these variables are already recorded on a last 7 day average per API so we didn't need to roll them\n",
    "    user_activity['score_training_frequency_WoW'] = user_activity['score_training_frequency'].pct_change(periods=7)\n",
    "    user_activity['score_training_volume_WoW'] = user_activity['score_training_volume'].pct_change(periods=7)\n",
    "    user_activity['score_meet_daily_targets_WoW'] = user_activity['score_meet_daily_targets'].pct_change(periods=7)\n",
    "    user_activity['score_recovery_time_WoW'] = user_activity['score_recovery_time'].pct_change(periods=7)\n",
    "    \n",
    "    #activity routine as the mean absolute value of WoW variables\n",
    "    user_activity['activity_routine_score'] = (\n",
    "    np.absolute(user_activity['score_training_frequency_WoW']) + \n",
    "    np.absolute(user_activity['score_training_volume_WoW']) +\n",
    "    np.absolute(user_activity['score_meet_daily_targets_WoW'])+\n",
    "    np.absolute(user_activity['score_recovery_time_WoW']))/4\n",
    "\n",
    "\n",
    "    user_activity.set_index('user_date', inplace = True)\n",
    "    activity = activity.append(user_activity)\n",
    "\n",
    "\n",
    "    #### ---------- READINESS FEATURES ----------- ####\n",
    "    # As we are not doing any transformation in the readiness data frame, append directly to the final one:\n",
    "    user_readiness['user_date'] = user_user['user_id'][0] + '|' + user_readiness['summary_date'].astype('str')\n",
    "    user_readiness.set_index('user_date', inplace=True)\n",
    "    readiness = readiness.append(user_readiness)\n",
    "\n",
    "    #### ---------- EXPERIMENTS FEATURES ----------- ####\n",
    "    # Not all users had experiments done:\n",
    "    if len(user_json['previousExperiments']) != 0:\n",
    "    # extract and flattens only the features needed: date, treatment, effect, and if if is a baseline date.\n",
    "    # NOTE: In Memento one experiment have one treatment, but can have multiple effects, however we are not interested\n",
    "    #       in the intermediate effect, but on the effect on final sleep score. Therefore, we will ignore the effects\n",
    "    #       the users set and incorporate the experiments to the main data frame.\n",
    "      \n",
    "        user_experiments = pd.DataFrame.from_records([i for i in user_json['previousExperiments']])\n",
    "        xp_counter += len(user_json['previousExperiments'])\n",
    "    \n",
    "        try:\n",
    "            treatment_randomized = pd.io.json.json_normalize(user_experiments.design[0]).isRandomized[0]\n",
    "        except:\n",
    "            treatment_randomized = 0\n",
    "        \n",
    "        # parse experiment types:\n",
    "        experiment_type = user_experiments.experimentName[0].split('(')[0]\n",
    "        \n",
    "        # unroll checkIns object\n",
    "        checkIns = pd.DataFrame()\n",
    "        checkIns = pd.io.json.json_normalize(user_experiments.checkIns[0])\n",
    "        \n",
    "        # add experiment randomization, type, and user_ids to checkins\n",
    "        checkIns['treatment_randomized'] = treatment_randomized\n",
    "        checkIns['experiment_type'] = experiment_type\n",
    "        checkIns['user_id'] = user_user['user_id'][0]\n",
    "        \n",
    "        # filter out only the necessary columns (helps the join later)\n",
    "        checkIns = checkIns.filter(['date','user_id','treatment_randomized','experiment_type','compliance'])\n",
    "    \n",
    "        checkIns['user_date'] = checkIns['user_id'] + '|' + checkIns['date'].astype('str')\n",
    "        checkIns.set_index('user_date', inplace=True)\n",
    "    \n",
    "        experiments = experiments.append(checkIns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log the time and main descriptive statistics of the final datasets for data governance purposes\n",
    "log_file.write(time.asctime() + ' - Feature space created. Time: ' + f'{(time.time() - start):.1f}' + ' secs.\\n')\n",
    "log_file.write(time.asctime() + '     - Total active users: ' + str(active_user_counter) + '\\n')\n",
    "log_file.write(time.asctime() + '     - ACTIVITY data frame shape: ' + str(activity.shape) + '\\n')\n",
    "log_file.write(time.asctime() + '     - SLEEP data frame shape: ' + str(sleep.shape) + '\\n')\n",
    "log_file.write(time.asctime() + '     - READINESS data frame shape: ' + str(readiness.shape) + '\\n')\n",
    "log_file.write(time.asctime() + '     - EXPERIMENTS data frame shape: ' + str(experiments.shape) + '\\n')\n",
    "log_file.write(time.asctime() + '       - finished EXPERIMENTS count: ' + str(xp_counter) + '\\n')\n",
    "log_file.write(time.asctime() + '       - finished EXPERIMENTS user-days: ' + str(experiments.shape[0]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge To One-Record-Per-Person-Per-Day, and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Save each DF as a csv file (case needed to work on a single file in teh future\n",
    "users_file_path = full_path + '/users_data.csv'\n",
    "sleep_file_path = full_path + '/sleep_data.csv'\n",
    "readiness_file_path = full_path + '/readiness_data.csv'\n",
    "activity_file_path = full_path + '/activity_data.csv'\n",
    "df_gold_file_path = full_path + '/gold.csv'\n",
    "experiments_file_path = full_path + '/experiments.csv'\n",
    "\n",
    "users.to_csv(users_file_path, index=None, encoding='utf-8')\n",
    "sleep.to_csv(sleep_file_path, index_label='user_date', encoding='utf-8')\n",
    "readiness.to_csv(readiness_file_path, index_label='user_Date', encoding='utf-8')\n",
    "activity.to_csv(activity_file_path, index_label='user_Date', encoding='utf-8')\n",
    "experiments.to_csv(experiments_file_path, index=None, encoding='utf-8')\n",
    "\n",
    "# Drop duplicate columns and merge all dfs in a big \"gold\" df. Will keep only one of the summary dates (readiness)\n",
    "readiness.drop(['period_id'], axis=1, inplace=True)\n",
    "sleep.drop(['summary_date', 'timezone','period_id'], axis=1, inplace=True)\n",
    "activity.drop(['bedtime_start', 'bedtime_end', 'summary_date', 'timezone', 'total'], axis=1, inplace=True)\n",
    "experiments.drop(['date', 'user_id'], axis=1, inplace=True)\n",
    "\n",
    "# merge all data frames into one. NOTE: sleep, activity and readiness are inner joins, so only days with all records are\n",
    "# used. For experiments we use outer join, so user_days without experiments will have NaN on those features.\n",
    "df_gold = sleep.merge(activity, left_index=True, right_index=True)\n",
    "df_gold = df_gold.merge(readiness, left_index=True, right_index=True)\n",
    "df_gold = df_gold.merge(experiments, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "#---adding experiment category and user_id indicators---#\n",
    "\n",
    "df_gold['experiment_category'] = df_gold['experiment_type'].apply(experiments_recategorize)\n",
    "df_gold = pd.get_dummies(df_gold, columns=['experiment_category','user_id'])\n",
    "\n",
    "#binarizing next week's sleep score: 0 if decrease, 1 otherwise\n",
    "df_gold['avg_sleep_score_next_week_binarized'] = (df_gold['avg_sleep_score_next_week'] >= df_gold['rol_sleep_score_7d']).astype(int)\n",
    "\n",
    "#---writing out to file----#\n",
    "df_gold.to_csv(df_gold_file_path, index_label='user_date', encoding='utf-8')\n",
    "\n",
    "log_file.write(time.asctime() + '     - GOLD data frame shape: ' + str(df_gold.shape) + '\\n')\n",
    "\n",
    "# zip all files in a gold_dataset.zip\n",
    "files = [users_file_path, sleep_file_path, readiness_file_path,\n",
    "         activity_file_path, df_gold_file_path, experiments_file_path]\n",
    "\n",
    "files_names = ['users_data.csv', 'sleep_data.csv', 'readiness_data.csv',\n",
    "         'activity_data.csv', 'gold.csv', 'experiments.csv']\n",
    "\n",
    "zip_file = full_path + '/gold_dataset.zip'\n",
    "zipObj = zipfile.ZipFile(zip_file, mode='w')\n",
    "\n",
    "for i in range(len(files)):\n",
    "    zipObj.write(files[i], arcname=files_names[i])    \n",
    "\n",
    "zipObj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# delete unzipped CSVs\n",
    "for i in range(len(files)):\n",
    "    os.remove(files[i])\n",
    "    \n",
    "log_file.write(time.asctime() + ' - All data frames saved and zipped. Time: ' + f'{(time.time() - start):.1f}' + ' secs.\\n')\n",
    "\n",
    "log_file.write(time.asctime() + ' - Total time spent in the routine: ' + f'{(time.time() - main_time_counter):.1f}' + ' secs.\\n')\n",
    "log_file.write(time.asctime() + ' ##### ----- DATA INGESTION ROUTINE FINALIZED ----- #####\\n\\n')\n",
    "\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data for Modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unzipping and Reading in Gold Dataset\n",
    "import zipfile\n",
    "unzip_file_path = full_path + '/unzipped_data'\n",
    "os.makedirs(unzip_file_path, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(unzip_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gold = pd.read_csv('data_ingestion/'+format(date.today().strftime('%Y-%m-%d'))+'/unzipped_data/gold.csv',parse_dates = ['summary_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Shape and Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Set Shape:\n",
      "(28873, 276)\n",
      "\n",
      "Training Data Columns:\n",
      "user_date, avg_sleep_score_next_week, awake, awake_norm, bedtime_end, bedtime_end_delta, bedtime_end_dev+1, bedtime_end_dev+2, bedtime_end_dev+3, bedtime_end_dev-1, bedtime_end_dev-2, bedtime_end_dev-3, bedtime_start, bedtime_start_delta, bedtime_start_dev+1, bedtime_start_dev+2, bedtime_start_dev+3, bedtime_start_dev-1, bedtime_start_dev-2, bedtime_start_dev-3, breath_average, deep, deep_D-1, deep_D-2, deep_norm, duration, duration_dev+1, duration_dev+2, duration_dev+3, duration_dev-1, duration_dev-2, duration_dev-3, duration_dev_0.0, efficiency, good_sleep, hr_5min, hr_average, hr_lowest, hypnogram_5min, is_longest, is_traveling, is_workday, light, light_norm, midpoint_at_delta, midpoint_time, onset_latency, onset_latency_norm, rem, rem_D-1, rem_D-2, rem_norm, restless, restless_norm, rmssd, rmssd_5min, rol_bedtime_end_delta_7d, rol_bedtime_start_delta_7d, rol_bedtime_start_delta_7d_WoW, rol_duration_7d, rol_duration_7d_WoW, rol_is_traveling_7d, rol_onset_latency_7d, rol_onset_latency_7d_WoW, rol_score_disturbances_7d, rol_score_disturbances_7d_WoW, rol_sleep_score_14d, rol_sleep_score_21d, rol_sleep_score_7d, score_alignment, score_deep, score_disturbances, score_efficiency, score_latency, score_rem, score_total, sleep_routine_score, sleep_score, sleep_score_D-1, sleep_score_D-2, temperature_delta, temperature_deviation, temperature_trend_deviation, total, tz_delta, weekday_fri, weekday_mon, weekday_sat, weekday_sun, weekday_thu, weekday_tue, weekday_wed, activity_routine_score, activity_score, afterwake_exercise_min, age, age_bin, average_met, beforesleep_exercise_min, cal_active, cal_total, class_5min, daily_movement, day_end, day_start, eve_exercise_min, height, height_bin, high, inactive, inactivity_alerts, is_male, low, medium, met_1min, met_min_high, met_min_inactive, met_min_low, met_min_medium, met_min_medium_plus, non_wear, noon_exercise_min, rest, rol_activity_score_7d, rol_afterwake_exercise_min_7d, rol_beforesleep_exercise_min_7d, rol_cal_total_7d, rol_eve_exercise_min_7d, rol_high_7d, rol_inactive_7d, rol_medium_7d, rol_met_min_high_7d, rol_met_min_medium_7d, rol_met_min_medium_plus_7d, rol_non_wear_7d, rol_noon_exercise_min_7d, rol_score_move_every_hour_7d, rol_score_stay_active_7d, rol_sleep_afterMidnight_7d, rol_steps_7d, score_meet_daily_targets, score_meet_daily_targets_WoW, score_move_every_hour, score_recovery_time, score_recovery_time_WoW, score_stay_active, score_training_frequency, score_training_frequency_WoW, score_training_volume, score_training_volume_WoW, sleep_afterMidnight, steps, target_calories, target_km, target_miles, to_target_km, to_target_miles, weight, weight_bin, readiness_score, score_activity_balance, score_hrv_balance, score_previous_day, score_previous_night, score_recovery_index, score_resting_hr, score_sleep_balance, score_temperature, summary_date, treatment_randomized, experiment_type, compliance, experiment_category_Chamomile Tea, experiment_category_Magnesium, experiment_category_Meditation, experiment_category_None, experiment_category_Other, user_id_35MFM6FVESRUSFVVT42XZ4EESW2QDWO6, user_id_3GFNJNPROVUFMPSYCY4I2ZHED5LF4IP4, user_id_3ODDBBH2X2M657BVIKGBR3GTXOM5RNEC, user_id_3RRCF34LLVBPDMZIH64OFRKQAHKRLLCO, user_id_3VFEKJTF2DXVNHMXSM7MHR3NLS6LD4ES, user_id_4GNMWE24LNFB3H2A63NKHCEGYJ6SK2VM, user_id_5FMMQSD6LRZMK2I6Q7UCZD7VCHNCLBMD, user_id_5LMPI32NNEM4SZZRNZWSLWJJMBH4BRI7, user_id_5NG5XEFS7SLWT4LUSCW4THSFO75SIWJ6, user_id_5OXXAWBOTMCWRHRP5IIGB3EUQR74GP7N, user_id_5YBPCHZWQV7Z3M2EHKJQR7VKKU4ZAABR, user_id_665MWIP5V5RKSFKZJJ5RCINMDJVHQPYN, user_id_75WRTQXVS7L5PLQ745ZJCKHI2YNBZU6Y, user_id_7EH7LJ2LATLAG4XXGGB4BJB6PV2HUJH5, user_id_7RODD5JSZEB5LD3QLYLL6UAP5Q6ALPVB, user_id_7YE7DHNBZC7OHB4HLMGCV5TRM5QM4OYM, user_id_AL5K2E56QSVWCQFQGSGRELQPVTKOAVRJ, user_id_ASAPPLHTMSEL7FWS5PFSDXOISXCUK3RN, user_id_AXDFBGOBVJ2XQMQ5VJNBGWU6EJZWB56H, user_id_BKSOOPTP226CTULYPCFRY6UJQUVAP44W, user_id_BSMMIBAIXMNSKRWKZLSHXA7VCBFFYQGK, user_id_C3VBZVHZ7GQBQ5ZQJ3WRISIZSCXREZFV, user_id_CAOTF7H2AP5N6QDF37SO4OMDOM7CTATJ, user_id_CCDHHTNYOR4KECZI2PVPTT7VBWV22KRJ, user_id_CKXJ3NECBUSLCG3VZR7D5UNJRV3XCQJN, user_id_COFYOGC575GXUOYHBTBV7AUC6WUPFPGE, user_id_D3SHPWN6RWVAL5HU6W6XZ5CX5FLP3V67, user_id_D4F2UYJHGCFG2ZWBH2IYBWHENG3KPJKG, user_id_DSFY2GOXDGCH42CZFQTRFUNT4VLU47WN, user_id_EFR5GF6DIOEH7IP7PUZOZMHQOWOIMCNE, user_id_EKMAYS6DRKEXV3YMDKNUOSFTFXEEVBY5, user_id_EVU662U4JR447Y4MSM6O5TNBX2MA3COH, user_id_FMRQ33SRZ2OFBXHVT37NA6PRQZOO4NHF, user_id_FUB6D44PNSJFMIJ5U6HNWBG2EG3CE7SE, user_id_FXSCJ3SR4L5VUG67ONITX35XHXVM6YWG, user_id_FYA4OXP4Z2K7TRL2PWHJVUA6DW2ZX2FZ, user_id_G4S6FQ4FGBFPZ3PAXUG2ANQWGIU4KVGF, user_id_G625HHCHCWI3VM34SWL47M4G7MMJBYR7, user_id_GKPPNGZF737SZAKO3XEWFBTIDUQR2GP2, user_id_GYIQA5ZQHUIZVHZTMYI2RDJENWPAZ5HY, user_id_H242KC2RBINYXOFIYW2HXZOXG72RKV7I, user_id_HE7LYDFE2U5ER6KFIGT6ZDIGEO7VNNOW, user_id_IJMYQTPY2PE7HCV3PKNMQFPQWV4TKIE4, user_id_IP26IE64PAU55MJSGIOU5ERGOJX5FER5, user_id_JCZWBWNSAIMC4AURKPGNI5MU42C7JK3Y, user_id_JEHBSVZW5BU6KIMXO2MDJHWVY7SZO5SX, user_id_JRXSQ3IHGUY5A72CRCJHZHJ3OXD3QRC5, user_id_JS5KEJ7K5GP4426GKYEGQRK4WMJPSWOP, user_id_JTSGXI32MOLULL3YCXQG7Q6NDRFP22YQ, user_id_K65QHWZZVBQVKFMKENIYPFFXWZLOGZXB, user_id_KYK7BJY3XUXT3YMLFUYITXJWOYU3BSML, user_id_LIQI5SGSWLLF2PWAG37HVERU3IQ56YNC, user_id_LPKT7EFPG3G2DQM5ZDE53OCJXL32VSEH, user_id_M3GQNIYHRR4MFNHM5ETTAAJEEYLS52LG, user_id_M66MESIGOACKFG6HV7A4RFOWUZ7WWGIO, user_id_MH3XWAJMRKHFE72O64QLI5QUPZHWEZ5G, user_id_N24GYPSARH67MJ3CIZXERX6QBCOLTDC5, user_id_NEZ7COKVOQ26GVP372HVBBPELVPLIRBH, user_id_NFDXWWBOEYFFXYZ7YXWCX3JUADIJCOVE, user_id_NJR7VMQYYXDZ45FOLV4PGOZVPXI3VRY5, user_id_NVQUZTMMEMPVCPVMTEFY5EDXMVVX7A64, user_id_OCXY4EIDIPHVNPMI7S4532A7LE3FCOHX, user_id_OIZO23IQ6BGVBMWG5QHIKGVMUR2UPUYY, user_id_OUU5ZTE7SJ3XI6LCEMGAACRTFC6ALW2B, user_id_P5Z7G2E2HN7ZYXBHVATGEDKVB54ZHJHL, user_id_PCHU6IQHQY5GCEQTCO7DVEUS5F4EJYBH, user_id_PDP4LTUST75KLPGTLVVH4ZNBHWP2N6WS, user_id_PGMUZ2RPGFIDZLOIP554ZNQELU4PFFO3, user_id_PQC6APVY4RN6ZBRKEOMFMGJDPCS67GDY, user_id_RRWWBSWLSV6BPRDSRFHNDLO7TAZNQ3VH, user_id_RYREDK2UBSQ5UJBUOFSCLUNKFUHFVNNT, user_id_S7KHBIGVM4FFA5VIVB4GHMB6ROTSR65L, user_id_SFGJB2Z7DD4IUSQOMJHOG4O2MJQ5EB6J, user_id_SVOVVGTMXMFCRMGNE6N4PCV6EA7GOUM7, user_id_T5X6JFT433GVZJ4SYJBWOU5HCO2JN7TZ, user_id_TAA3QDDZ4Y66YDRTZTVDWR7ELOUD7YBR, user_id_TE2CPSSWP4QUGFAJQZ5FHITIKPNCCICX, user_id_TNW7YYC4H2VYZRDXQRTHMGQJZSSUHM6X, user_id_TOCZTTWDTEIXG76C2FLILMGT3TTWW2CQ, user_id_U4IIJPEFGAKDRI4K7KUJVJRF5S7ZRHH5, user_id_U7DE247XPEMCU7NOFOVNEC5HKWVNILEV, user_id_UEBVTTCGFDZ6U3ATPSOR4ZABFJ6RGKNA, user_id_UIL4MTGKYFCCXFKCKISRFUTYNPNMEYHF, user_id_UZNLIVG56OJ2YYIUWHQZ4IOPJ7YBSEOE, user_id_VCFFO3Z4VIZBSW4ZDKS7JDWPI2JFMLH7, user_id_VFSI32SZ4SPYR7NXPGKGXUBKCDH5M247, user_id_VV7R7TC2LTMGAMNMY3CUCUGTUCWZUXWR, user_id_WVUK2CBNFCSLOMBB6XAHBDIQ5RETOHDG, user_id_WXTBDYGYQXTTIWODVGNBNK4IIUGNTPDX, user_id_X3KF7PN5SZMZ7R3K5EK5WNOMFYW5OYKA, user_id_X4B2PWSKOJKCIJC3JU7W4QW3AKNWXA7T, user_id_XDPDCV254I6GMSVFCMTLP25GCVZOQGCM, user_id_XWISH4KW6U4NGIJXJ7WES5CUXQH6OXJP, user_id_XYVULCP6S5EMI5JU2LCELQ6NMPAXOS2A, user_id_YAA6LITNNXM2LH2647SLP2JCGC5G7UI3, user_id_YXPKWLMQR3VLNCAUP4HPG2U2NMIZM52B, user_id_ZCJQTLO5JAXRAI63MNUHG2GVOWG6JKMS, user_id_ZGNWC32OXKEJBATPPJUFVMYQHU4L63SJ, avg_sleep_score_next_week_binarized, "
     ]
    }
   ],
   "source": [
    "# show dimensions of the training and test data at this stage\n",
    "print(\"\\nTrain Set Shape:\")\n",
    "print(df_gold.shape)\n",
    "\n",
    "print(\"\\nTraining Data Columns:\")\n",
    "for i in df_gold.columns:\n",
    "    print(i,end=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, accuracy_score, mean_squared_error,mean_absolute_error,explained_variance_score,median_absolute_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns for inclusion in modeling\n",
    "model_columns = [# time index\n",
    "                'summary_date',\n",
    "                # features constructed from Oura ring telemetry\n",
    "                'rol_sleep_afterMidnight_7d','rol_onset_latency_7d',\n",
    "                'rol_bedtime_start_delta_7d','rol_steps_7d','rol_is_traveling_7d',\n",
    "                'score_training_frequency', 'score_training_volume',\n",
    "                'activity_routine_score','sleep_routine_score',\n",
    "                'rol_score_disturbances_7d','rol_sleep_score_7d',\n",
    "                # features gathered on Oura signup\n",
    "                'is_male','age',\n",
    "                # binary features constructed from Bioloop experiments\n",
    "                'experiment_category_Chamomile Tea',\n",
    "                'experiment_category_Magnesium',\n",
    "                'experiment_category_Meditation',\n",
    "                # outcome feature\n",
    "                'avg_sleep_score_next_week'\n",
    "                ]\n",
    "\n",
    "# keep only selected columns\n",
    "mod_df = df_gold.filter(model_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting training and test set by recency\n",
    "train = mod_df[mod_df['summary_date'] <= pd.Timestamp(2019, 9, 1, 12)]\n",
    "test = mod_df[mod_df['summary_date'] > pd.Timestamp(2019, 9, 1, 12)]\n",
    "\n",
    "# dropping summary date since its not needed after train/test split on recency\n",
    "train = train.drop(['summary_date'],axis=1)\n",
    "test = test.drop(['summary_date'],axis=1)\n",
    "\n",
    "# dropping NaNs\n",
    "train = train.dropna()\n",
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Evaluate Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 of:  0.6969053662947778\n",
      "MSE of:  14.86953064187702\n",
      "MAE of:  3.0073587916179148\n",
      "Explained Variance: 0.6976523421599296\n",
      "Median Absolute Error 2.5128571428571647\n"
     ]
    }
   ],
   "source": [
    "#drop summary date from features\n",
    "features = [f for f in model_columns if f not in {'summary_date',\n",
    "                                                  'avg_sleep_score_next_week'}]\n",
    "\n",
    "# initialize Random Forest\n",
    "rf_regr = RandomForestRegressor(n_estimators = 100)\n",
    "\n",
    "# train the model\n",
    "rf_regr.fit(train[features],train['avg_sleep_score_next_week'])\n",
    "rf_reg_pred = rf_regr.predict(test[features])\n",
    "\n",
    "# test performance of the model\n",
    "print('R2 of: ',r2_score(test['avg_sleep_score_next_week'], rf_reg_pred))\n",
    "print('MSE of: ', mean_squared_error(test['avg_sleep_score_next_week'], rf_reg_pred))\n",
    "print('MAE of: ', mean_absolute_error(test['avg_sleep_score_next_week'], rf_reg_pred))\n",
    "print('Explained Variance:', explained_variance_score(test['avg_sleep_score_next_week'], rf_reg_pred))\n",
    "print('Median Absolute Error',median_absolute_error(test['avg_sleep_score_next_week'], rf_reg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.9913\n",
       "                \n",
       "                    &plusmn; 0.0263\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                rol_sleep_score_7d\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.78%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0731\n",
       "                \n",
       "                    &plusmn; 0.0073\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                rol_score_disturbances_7d\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.23%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0588\n",
       "                \n",
       "                    &plusmn; 0.0053\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                age\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.71%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0198\n",
       "                \n",
       "                    &plusmn; 0.0048\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                rol_steps_7d\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.80%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0179\n",
       "                \n",
       "                    &plusmn; 0.0016\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                rol_bedtime_start_delta_7d\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.98%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0142\n",
       "                \n",
       "                    &plusmn; 0.0025\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                rol_sleep_afterMidnight_7d\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.54%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0045\n",
       "                \n",
       "                    &plusmn; 0.0017\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                is_male\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.71%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0024\n",
       "                \n",
       "                    &plusmn; 0.0023\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                rol_onset_latency_7d\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.72%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0022\n",
       "                \n",
       "                    &plusmn; 0.0007\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                sleep_routine_score\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.88%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0007\n",
       "                \n",
       "                    &plusmn; 0.0006\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                score_training_frequency\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                experiment_category_Chamomile Tea\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.99%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0000\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                experiment_category_Meditation\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.97%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0001\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                experiment_category_Magnesium\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.94%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0003\n",
       "                \n",
       "                    &plusmn; 0.0007\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                activity_routine_score\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.89%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0006\n",
       "                \n",
       "                    &plusmn; 0.0017\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                score_training_volume\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 99.88%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0007\n",
       "                \n",
       "                    &plusmn; 0.0023\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                rol_is_traveling_7d\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "# compute permutation importance\n",
    "perm = PermutationImportance(rf_regr, random_state=1).fit(test[features], test['avg_sleep_score_next_week'])\n",
    "\n",
    "# display feature weights\n",
    "eli5.show_weights(perm, feature_names = test[features].columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Performance to Naive Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 of:  0.6620695462141999\n",
      "MSE of:  17.047719087635052\n",
      "MAE of:  3.1461812573130525\n",
      "Explained Variance: 0.6621109695163228\n",
      "Median Absolute Error 2.5714285714285694\n"
     ]
    }
   ],
   "source": [
    "# use last 7 days of sleep as a naive carry-forward predictor\n",
    "baseline_features = 'rol_sleep_score_7d'\n",
    "\n",
    "# test performance of naive predictor\n",
    "print('R2 of: ' ,r2_score(test[baseline_features],test['avg_sleep_score_next_week']))\n",
    "print('MSE of: ', mean_squared_error(test[baseline_features],test['avg_sleep_score_next_week']))\n",
    "print('MAE of: ', mean_absolute_error(test[baseline_features],test['avg_sleep_score_next_week']))\n",
    "print('Explained Variance:', explained_variance_score(test[baseline_features],test['avg_sleep_score_next_week']))\n",
    "print('Median Absolute Error',median_absolute_error(test[baseline_features],test['avg_sleep_score_next_week']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predicted_sleep_score_model_sklearn.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model to file\n",
    "from joblib import dump, load\n",
    "dump(rf_regr, 'predicted_sleep_score_model_sklearn.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
